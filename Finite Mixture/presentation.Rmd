---
title: 'Evaluation of KNN classifier with Principal Component Analysis'
author: "Matteo Fasulo, Simone Flavio Paris, Matteo Sivoccia"
date: "07/12/2021"
output:
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
    number_sections: yes
    toc_float: yes
    theme: united
    highlight: tango
    code_folding: hide
  html_notebook:
    toc: yes
    toc_depth: 3
    number_sections: yes
    toc_float: yes
    theme: united
    highlight: tango
    df_print: paged
    code_folding: hide
---
Packages used:

```{r Pre Processing, message=FALSE, warning=FALSE}
source("https://raw.githubusercontent.com/MatteoFasulo/Rare-Earth/main/R/util/coreFunctions.R")
loadPackages(c('pacman','ggplot2','sn','corrplot','FactoMineR','factoextra',
               'caret','tidyverse','rgl'))
pacman::p_loaded()
data(wines)
```

# Dataset
Riassunto del dataset:

```{r wines, message=FALSE, warning=FALSE, paged.print=TRUE}
wines
```

# Correlation Matrix
Abbiamo deciso, per prima cosa, di controllare la correlazione tra le variabili attraverso una rappresentazione grafica dove sia l'intensità del colore che il raggio di ogni circonferenza è proporzionale alla correlazione della variabile.

```{r corMatrix, message=FALSE, warning=FALSE}
corMatrix <- cor(wines[,-1])
plotCorr <- function(corMatrix){
  col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
  return(corrplot(corMatrix,
                  type="upper",
                  order="FPC",
                  sig.level = 0.01,
                  insig = "blank",
                  title = 'Correlation Plot',
                  tl.cex = .8,
                  mar=c(0,0,1,0)))
}
plotCorr(corMatrix)
```

Ci è sembrato opportuno nella nostra analisi considerare anche l'annata del vino ottenuta dalla trasformazione del nome di ogni osservazione.

```{r year, message=FALSE, warning=FALSE, paged.print=TRUE}
year <- as.numeric(substr(rownames(wines), 6, 7))
wines[,'year'] <- year

wines %>%
    count(wine = factor(wine),
          year = factor(year)) %>%
    mutate(pct = prop.table(n)) %>% 
    ggplot(aes(x = year, y = pct, fill = wine, label = scales::percent(pct))) + 
    geom_col(position = 'stack') + 
    geom_text(position = position_stack(vjust = 0.5),
              size = 3) + 
    scale_y_continuous(name = "Percentage")+
    scale_x_discrete(name = "Year")+
    scale_fill_manual(values=c("#CC6666", "#9999CC", "#66CC99"))+
    theme(legend.position = "bottom")
```

# PCA
Utilizzando la Principal Component Analysis abbiamo stimato le componenti principali che descrivono il nostro dataset, con l'aggiunta di 2 variaibli qualitative di supporto:

- Tipo di vino (Barolo, Barbera, Grignolino)
- Annata del vino

```{r pca, message=FALSE, warning=FALSE, include=FALSE}
res <- PCA(wines, quanti.sup=NULL, quali.sup=c(1,29))
```

## Screeplot
Dallo screeplot è possibile visualizzare la percentuale di varianza spiegata dalle componenti principali. Si noti come solamente le prime 2 costituiscono il 41% della varianza totale.

```{r screeplot, message=FALSE, warning=FALSE}
fviz_screeplot(res, addlabels = TRUE, ylim = c(0, 26))
```

Riassunto dell'analisi delle componenti principali:

```{r summaryPCA, message=FALSE, warning=FALSE}
summary(res, nbelements=10)
```

## Individuals Plot
La libreria _*fviz*_ ci ha permesso di rappresentare graficamente gli individui in funzione delle prime due componenti principali. Per semplicità di rappresentazione, vengono mostrati gli individui il cui cos2 è maggiore di 0.6 .

```{r individual, message=FALSE, warning=FALSE}
fviz_pca_ind(res,
             col.ind="cos2",
             geom = c("point","text"),
             gradient.cols = c("#94bdff","#1b7fcc",'#00062e'),
             repel=T,
             select.ind= list(cos2 = .6),
             ggtheme=theme_minimal())
```

CONSIDERAZIONI A RIGUARDO

## Variables Plot
Discorso analogo per quanto riguarda le variabili, selezionando le top 10 per cos2.

```{r variablesPCA, message=FALSE, warning=FALSE}
fviz_pca_var(res, col.var = "cos2",
             gradient.cols = c("#94bdff","#1b7fcc",'#00062e'),
             select.var= list(cos2 = 10),
             repel = T,
             ggtheme = theme_minimal())
```

## What's Dim1 and Dim2?
```{r description of variables, message=FALSE, warning=FALSE, paged.print=TRUE, rows.print=27}
descDf <- data.frame("Category"=c('Alcohol/fermentation',NA,NA,NA,'Taste',NA,NA,NA,NA,NA,NA,NA,NA,'Mineral content',NA,NA,NA,NA,'Appearance',NA,NA,NA,'Other chemical elements',NA,NA,NA,NA),
                    "Variable"=c('Alcohol','Proline','Glycerol','Methanol','Phenols','NonFlavanoids','Flavanoids','Sugar','Acidity','Malic','Tartaric','Uronic','Proanthocyanins','Ash','Alcal-Ash','Magnesium','Potassium','Calcium','Hue','Colour','OD_dw','OD_fl','pH','Phosphate','Chloride','Butanediol','Nitrogen'),
                    "Dim"=c(2,2,NA,NA,1,NA,1,NA,1,NA,NA,1,NA,NA,NA,NA,NA,NA,1,2,1,1,NA,NA,NA,NA,NA))
data_blank <- descDf
data_blank <- sapply(data_blank, as.character)
data_blank[is.na(data_blank)] <- "" 
as.data.frame(data_blank)
```

Abbiamo analizzato quali siano le variabili principali riassunte da ogni variabile sintetica, abbiamo notato alti valori del cos2 per la DIM1 con:

- Phenols
- Flavanoids
- Acidity
- Uronic
- Hue
- OD_dw
- OD_fl

Considerando che:

- le prime 4 variabili appartengono alla categoria *taste*
- *OD_dw* e *OD_fl* sono fortemente correlate a queste variabili nella *Correlation Matrix*

La dimensione 1 rappresenta principalmente l' __intensità del sapore__.


Sulla dimensione 2 vi sono principalmente:

- Alcohol
- Proline
- Colour

E considerando che:

- Sia *Alcohol* che *Proline* sono misure della categoria di *Alcohol*/*fermentation*
- *Colour* è correlato positivamente con *Alcohol* nella *Correlation Matrix*

E' ragionevole pensare che la dimensione 2 rappresenti i **livelli di fermentazione** e di **alcol**.

## BiPlot
Combinando insieme le due precedenti rappresentazioni:

```{r biplotPCA-1-2, message=FALSE, warning=FALSE}
fviz_pca_biplot(res, label = "var", habillage=wines$wine,
                addEllipses=TRUE, ellipse.level=0.90,
                ggtheme = theme_minimal(),
                select.var= list(cos2 = 10))
```
Possiamo notare come la dimensione 1 oppone (divide) in maniera forte i vini Barolo e Barbera.

I Barolo sono caratterizzati da:
- **Alti valori** di *flavanoids*, *proline*, *phenols*, *OD_dw*, *alcohol*, *hue*. (variabili ordinate in maniera decrescente)
- **Bassi valori** di *year* (sono quelli più vecchi infatti), *alcal_ash*, *acidity*

I Barbera sono caratterizzati da: (valori diversi in grassetto)
- **Alti valori** di *acidity*, *year* (sono quelli più recenti infatti), **tartaric**, **malic**, **uronic**, *alcal_ash* e **colour** (variabili ordinate in maniera decrescente)
- **Bassi valori** di  *OD_dw*,  **OD_fl**, *flavanoids*, *hue*, *phenols*, **roanthocyanins**, *proline*. 

La dimensione 2 divide discretamente i Grignolino dai Barolo e Barbera.
I Grignolino sono caratterizzati da:
- **Alti valori** di *OD_fl*, **calcium**, *hue*.
- **Bassi valori** di  *alcohol*,  *colour*, *ash*, *proline*, **magnesium**, **glycerol**, **sugar**. 
Notiamo anche che **i Grignolino sono altamente correlati con questa dimensione**, infatti possono riassumere da soli la dimensione 2.

## Ellipses Plot
Considerando inoltre il fattore annata del vino:

```{r ellipsesPCA-1-2, message=FALSE, warning=FALSE}
plotellipses(model=res, autoLab = "auto")
```

## What about 3rd and 4th dimension?
Per scrupolo, abbiamo controllato anche le componenti principali successive alla prima e seconda dimensione, notando che le osservazioni, sulla terza e quarta dimensione, non sono ben distinguibili.

```{r biplotPCA-3-4, message=FALSE, warning=FALSE}
fviz_pca_biplot(res, axes=c(3,4), label = "var", habillage=wines$wine,
                addEllipses=TRUE, ellipse.level=0.90,
                ggtheme = theme_minimal())
```                

```{r ellipsesPCA-3-4, message=FALSE, warning=FALSE}
plotellipses(model=res, axes=c(3,4), autoLab = "auto")

```

# Splitting (using caret)
Volendo dunque utilizzare le componenti principali come base per una classificazione, abbiamo recuperato gli score per ogni osservazione dalle due dimensioni (DIM1 e DIM2), e diviso il dataset originario in una sezione di training ed una di testing. Lo split è effettuato secondo una proporzione di 0.7:

```{r splitting, message=FALSE, warning=FALSE}
set.seed(3033)
intrain <- createDataPartition(y = wines$wine, p=0.7, list = FALSE)
dim(intrain)
```

# KNN {.tabset}
Combinando in un unico dataframe i risultati della prima e della seconda componente principale è stato possibile applicare, tra i tanti metodi di classificazione, il KNN (K Nearest Neighbours) con Cross Validation 10-Fold: 

```{r principal components, message=FALSE, warning=FALSE}
pc.comp <- res$ind$coord
pc.comp1 <- pc.comp[,1]
pc.comp2 <- pc.comp[,2]
X = cbind(pc.comp1, pc.comp2)
X = as.data.frame(cbind(wine=wines$wine, X))
X[which(X$wine==1),1] <- "Barolo"
X[which(X$wine==2),1] <- "Grignolino"
X[which(X$wine==3),1] <- "Barbera"
```

## KNN-PC1 
```{r knnPC1, message=FALSE, warning=FALSE}
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit.PC1 <- caret::train(wine ~ .-pc.comp2, data = X[intrain,], method = "knn",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 10)
print(knn_fit.PC1)
plot(knn_fit.PC1)
test_pred <- predict(knn_fit.PC1, newdata = X[-intrain,])
confusionMatrix(test_pred, as.factor(X[-intrain,'wine']))
```

## KNN-PC2 
```{r knnPC2, message=FALSE, warning=FALSE}
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit.PC2 <- caret::train(wine ~ .-pc.comp1, data = X[intrain,], method = "knn",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 10)
print(knn_fit.PC2)
plot(knn_fit.PC2)
test_pred <- predict(knn_fit.PC2, newdata = X[-intrain,])
confusionMatrix(test_pred, as.factor(X[-intrain,'wine']))
```
## KNN-PC1+PC2 
```{r knnPC1+PC2, message=FALSE, warning=FALSE}
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit.PC12 <- caret::train(wine ~ ., data = X[intrain,], method = "knn",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 10)
print(knn_fit.PC12)
plot(knn_fit.PC12)
test_pred <- predict(knn_fit.PC12, newdata = X[-intrain,])
confusionMatrix(test_pred, as.factor(X[-intrain,'wine']))
```

## KNN (without PCA)
```{r knnNoPCA, message=FALSE, warning=FALSE}
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(3333)
knn_fit <- train(wine ~.-year, data = wines[intrain,], method = "knn",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 10)
print(knn_fit)
plot(knn_fit)

test_pred <- predict(knn_fit, newdata = wines[-intrain,])
confusionMatrix(test_pred, as.factor(wines[-intrain,1]))
```

## KNN comparison
```{r knn Comparison, message=FALSE, warning=FALSE}
knn.accuracyData = as.data.frame(cbind(PC1 = knn_fit.PC1$results$Accuracy,
                                       PC2 = knn_fit.PC2$results$Accuracy,
                                       PC12= knn_fit.PC12$results$Accuracy,
                                       NO_PCA = knn_fit$results$Accuracy))

ggplot(knn.accuracyData, aes(knn_fit.PC1$results$k)) + 
  geom_line(aes(y = PC1, colour = "PC1"), size=1) + geom_point(aes(y = PC1)) +
  geom_line(aes(y = PC2, colour = "PC2"), size=1) + geom_point(aes(y = PC2)) +
  geom_line(aes(y = PC12, colour = "PC1&2"), size=1) + geom_point(aes(y = PC12)) +
  geom_line(aes(y = NO_PCA, colour = "Normal"), size=1) + geom_point(aes(y = NO_PCA)) +
  scale_color_manual(name = "Y series", values = c("PC1" = "#003fa3", "PC2" = "#00a375", "PC1&2" = "#9800a3", "Normal" = "#a3003c")) +
  ggtitle("Comparison between Components") +
  xlab("#Neighbors") + ylab("Accuracy (Repeated Cross Validation)")
```

# Modellazione 3D
```{r 3ds, message=FALSE, warning=FALSE}
# best 3 for separation
plot3d(wines$flavanoids, wines$OD_dw, wines$proline, type='s', size=2, col=as.numeric(wines$wine))
# worst 3 for separation
plot3d(wines$methanol, wines$potassium, wines$pH, type='s', size=2, col=as.numeric(wines$wine))
```

# Modellazione 3D PCA
```{r 3ds PCA, message=FALSE, warning=FALSE}
# Migliori 3 per PCA che spiegano il 50,55% della varianza
plot3d(pc.comp[,1], pc.comp[,2], pc.comp[,3], type='s', size=2, col=as.numeric(wines$wine))
pc.comp[,1]
```
